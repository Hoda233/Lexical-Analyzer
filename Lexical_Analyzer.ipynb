{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "alphanumeric='abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
    "dot =  '('+('|'.join(alphanumeric))+')'\n",
    "\n",
    "# print(dot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex to Postfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|0|1|2|3|4|5|6|7|8|9)\n",
      "(a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|0|1|2|3|4|5|6|7|8|9)\n",
      "(a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|0|1|2|3|4|5|6|7|8|9)\n",
      "ab|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|0|1|2|3|4|5|6|7|8|9|\n",
      "ab|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z|A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|0|1|2|3|4|5|6|7|8|9|\n"
     ]
    }
   ],
   "source": [
    "def validate_regex(regex):\n",
    "    try:\n",
    "       re.compile(regex)\n",
    "       return True\n",
    "    except:\n",
    "       return False \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def handle_dot(regex):\n",
    "   return re.sub(r'\\.', dot, regex)\n",
    "\n",
    "def handle_range(regex):\n",
    "    new_regex = \"\"\n",
    "    replace = False\n",
    "    start = None\n",
    "    end= None\n",
    "    for i in range(len(regex)):\n",
    "        if regex[i] == '[':\n",
    "            new_regex += '('\n",
    "            replace =True\n",
    "        elif regex[i]== ']':\n",
    "             new_regex += ')'\n",
    "             replace =False\n",
    "        elif regex[i] == '-':\n",
    "            replace = True\n",
    "            start = alphanumeric.index(regex[i-1])\n",
    "            end = alphanumeric.index(regex[i+1])\n",
    "            for j in range(start+1,end):\n",
    "                new_regex += alphanumeric[j]\n",
    "                if(replace and regex[i+1] != ']'):\n",
    "                    new_regex+='|'\n",
    "        else:\n",
    "           new_regex += regex[i] \n",
    "           if(replace and regex[i+1] != ']'):\n",
    "                    new_regex+='|'\n",
    "\n",
    "\n",
    "    return new_regex  \n",
    "\n",
    "\n",
    "def concatenate(regex):\n",
    "    new_regex = \"\"\n",
    "    for i in range(len(regex)-1):\n",
    "        new_regex += regex[i] \n",
    "        if regex[i] in ['*','+','?',')',']'] and regex[i+1] not in ['*','+','?',')',']','.', '|']:\n",
    "            new_regex+=\".\"\n",
    "        elif regex[i] in alphanumeric and  (regex[i+1] in alphanumeric or regex[i+1] in ['(','[']):\n",
    "            new_regex+=\".\"\n",
    "    \n",
    "    new_regex += regex[-1]\n",
    "\n",
    "    return new_regex\n",
    "\n",
    "def infix_to_postfix(regex):\n",
    "    queue = []\n",
    "    stack = []\n",
    "    operators={'(':0,\"|\":1, \".\":2, \"?\":3, \"+\":4, \"*\":5}\n",
    "\n",
    "    for i in range(len(regex)):\n",
    "        if regex[i] == '(':\n",
    "            stack.append(regex[i])\n",
    "        elif regex[i] == ')':\n",
    "            while stack[-1] != \"(\":  \n",
    "                queue.append(stack.pop()) \n",
    "            stack.pop()     \n",
    "        elif regex[i] in operators:\n",
    "            while stack  and operators[regex[i]] <= operators[stack[-1]]:\n",
    "                queue.append(stack.pop())\n",
    "            stack.append(regex[i])\n",
    "\n",
    "        else :\n",
    "            queue.append(regex[i])    \n",
    "    \n",
    "    while stack:\n",
    "        queue.append(stack.pop())\n",
    "\n",
    "    return ''.join(queue  )  \n",
    "\n",
    "\n",
    "def to_postfix(regex):\n",
    "    if(validate_regex(regex)):\n",
    "       regex = handle_dot(regex)\n",
    "       print(regex)\n",
    "       regex = handle_range(regex)\n",
    "       print(regex)\n",
    "       regex = concatenate(regex)\n",
    "       print(regex)\n",
    "       regex = infix_to_postfix(regex)\n",
    "       print(regex)\n",
    "\n",
    "       return regex\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('sorry you have entered invalid regex! ')    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# print(handle_dot('ab.c'))\n",
    "# print(handle_range(\"[a-z]+abc[Abc]*[1-5]\"))\n",
    "# print(concatenate(\"a+b*|c(5.f)\"))\n",
    "# print(infix_to_postfix(\"(A+.B*)?.(C|D)\"))\n",
    "print(to_postfix(\".\"))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postfix to NFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class edge:\n",
    "    def __init__(self):\n",
    "       self.label=None\n",
    "       self.destination=None\n",
    "\n",
    "\n",
    "class state:\n",
    "       def __init__(self):\n",
    "        self.label=None\n",
    "        self.outgoing_edges=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NFA:    \n",
    "       def __init__(self, start, accept,states):\n",
    "        self.start_state = start\n",
    "        self.acceptance_state = accept\n",
    "        self.states = states\n",
    "        \n",
    "\n",
    "def construct_nfa (label, id, stack):\n",
    "    start = state()\n",
    "    acceptance = state()\n",
    "    start.label = \"S\"+str(id)\n",
    "    acceptance.label = \"S\"+str(id+1)\n",
    "\n",
    "    Edge = edge()\n",
    "    Edge.label = label\n",
    "    Edge.destination = acceptance \n",
    "    start.outgoing_edges.append(Edge)\n",
    "\n",
    "    result_nfa = NFA(start, acceptance, [start,acceptance])\n",
    "    stack.append(result_nfa)\n",
    "    #print(result_nfa.inner_states)\n",
    "\n",
    "    return result_nfa, id+2\n",
    "\n",
    "\n",
    "def nfa_concatination (stack):\n",
    "   \n",
    "    \n",
    "    nfa2 = stack.pop()\n",
    "    nfa1 = stack.pop()\n",
    "\n",
    "\n",
    "    Edge = edge()\n",
    "    Edge.label = 'ε'\n",
    "    Edge.destination = nfa2.start_state\n",
    "    nfa1.acceptance_state.outgoing_edges.append(Edge)\n",
    "\n",
    "    #print(nfa1)\n",
    "    #print(nfa1.inner_states)\n",
    "\n",
    "    resultnfa = NFA(nfa1.start_state,  nfa2.acceptance_state, nfa1.states + nfa2.states)\n",
    "    stack.append(resultnfa)\n",
    "    return resultnfa\n",
    "\n",
    "\n",
    "def nfa_or (stack, id):\n",
    "  nfa1 = stack.pop()\n",
    "  nfa2 = stack.pop()\n",
    "  newStart = state()\n",
    "  newStart.label= \"S\"+str(id)\n",
    "  newEnd = state()\n",
    "  newEnd.label = \"S\"+str(id+1)\n",
    "\n",
    "  Edge1 = edge()\n",
    "  Edge1.label = 'ε'\n",
    "  Edge1.destination = nfa1.start_state\n",
    "\n",
    "  Edge2 = edge()\n",
    "  Edge2.label = 'ε'\n",
    "  Edge2.destination = nfa2.start_state\n",
    "\n",
    "  newStart.outgoing_edges.append(Edge1)\n",
    "  newStart.outgoing_edges.append(Edge2)\n",
    "\n",
    "\n",
    "  Edge3 = edge()\n",
    "  Edge3.label = 'ε'\n",
    "  Edge3.destination = newEnd\n",
    "\n",
    "  nfa1.acceptance_state.outgoing_edges.append(Edge3)\n",
    "\n",
    "  Edge4 = edge()\n",
    "  Edge4.label = 'ε'\n",
    "  Edge4.destination = newEnd\n",
    "  nfa2.acceptance_state.outgoing_edges.append(Edge4)\n",
    "\n",
    "\n",
    "  result = NFA(newStart, newEnd, [newStart,newEnd]+ nfa1.states + nfa2.states)\n",
    "  stack.append(result)\n",
    "  return result, id+2\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def nfa_json (nefa:NFA):\n",
    "  outputJson = dict()\n",
    "  outputJson[\"startingState\"] = nefa.start_state.label\n",
    "  for stat in nefa.states:\n",
    "    stateDict = dict()\n",
    "    if stat == nefa.acceptance_state:\n",
    "      stateDict[\"isTerminatingState\"] = True\n",
    "    else:\n",
    "      stateDict[\"isTerminatingState\"] = False\n",
    "    for edg in stat.outgoing_edges:\n",
    "      if(edg.label in stateDict.keys()):\n",
    "        stateDict[edg.label] = [] + [stateDict[edg.label]] + [edg.destination.label]\n",
    "      else:\n",
    "        stateDict[edg.label] = edg.destination.label\n",
    "    outputJson[stat.label] = stateDict\n",
    "  nfaOutFile = open('NFA.json', 'w')\n",
    "  JsonObject = json.dump(outputJson, nfaOutFile,indent=6, ensure_ascii=False)\n",
    "  nfaOutFile.close()\n",
    "  return JsonObject\n",
    "\n",
    "def postfix_to_nfa(postfix):\n",
    "     stack = []\n",
    "     id = 1\n",
    "\n",
    "     for i in range(len(postfix)):\n",
    "         if postfix[i] in alphanumeric:\n",
    "           _ ,id =  construct_nfa(postfix[i],id,stack)\n",
    "         elif postfix[i] == '.':   \n",
    "             nfa_concatination(stack) \n",
    "         elif postfix[i] == '|':   \n",
    "            _,id = nfa_or(stack,id)     \n",
    "     result = stack.pop()\n",
    "     return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(a|b)\n",
      "(a|b)\n",
      "(a|b)\n",
      "ab|\n"
     ]
    }
   ],
   "source": [
    "postfix = to_postfix(\"(a|b)\")\n",
    "nfa = postfix_to_nfa(postfix)\n",
    "json_obj = nfa_json(nfa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFA to DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon_closure(nfa, input_state):\n",
    "\n",
    "    stack = [input_state]\n",
    "    closure = set()\n",
    "\n",
    "    while stack:\n",
    "\n",
    "        current_state = stack.pop()\n",
    "        closure.add(current_state)\n",
    "\n",
    "        if \"ε\" in nfa[current_state]:\n",
    "\n",
    "            next_states = nfa[current_state][\"ε\"]\n",
    "            if isinstance(next_states, str):\n",
    "                next_states = [next_states]\n",
    "\n",
    "            for state in next_states:\n",
    "                if state not in closure:\n",
    "                    stack.append(state)\n",
    "                    closure.add(state)\n",
    "\n",
    "    return tuple(sorted(closure))\n",
    "\n",
    "def convert_nfa_to_dfa(nfa):\n",
    "\n",
    "    nfa_start_state = nfa[\"startingState\"]\n",
    "    dfa_start_state = get_epsilon_closure(nfa,nfa_start_state)\n",
    "\n",
    "    dfa = {}\n",
    "    dfa[\"startingState\"] = dfa_start_state\n",
    "\n",
    "    stack = [dfa_start_state]\n",
    "\n",
    "    while stack:\n",
    "        current_state = stack.pop()\n",
    "        dfa[current_state] = {}     #current_state = (s0,s1,s2) \n",
    "        dfa[current_state][\"isTerminatingState\"] = False\n",
    "\n",
    "        for state in current_state:\n",
    "            nfa_state = nfa[state]   # nfa_state -> dic of s0 in nfa\n",
    "\n",
    "            for sub_key in nfa_state:\n",
    "\n",
    "                if sub_key == \"isTerminatingState\":\n",
    "                    dfa[current_state][\"isTerminatingState\"] |= nfa_state[\"isTerminatingState\"]\n",
    "\n",
    "                elif sub_key != \"ε\": # edges of s0\n",
    "                    next_states = get_epsilon_closure(nfa,nfa_state[sub_key])\n",
    "                    if sub_key in dfa[current_state]: # if edge already in dfa state\n",
    "                        temp_set= set(dfa[current_state][sub_key])\n",
    "                        temp_set.update(next_states)\n",
    "                        dfa[current_state][sub_key] = tuple(sorted(temp_set))\n",
    "                    else:\n",
    "                        dfa[current_state][sub_key] = next_states\n",
    "        \n",
    "        for new_sub_key in dfa[current_state]:\n",
    "            if new_sub_key != \"isTerminatingState\":\n",
    "                new_added_state = dfa[current_state][new_sub_key]\n",
    "                if new_added_state not in dfa:\n",
    "                    stack.append(new_added_state)\n",
    "\n",
    "    return dfa\n",
    "\n",
    "def get_final_dfa(dfa):\n",
    "\n",
    "    # create a dict for states with their new names\n",
    "    new_states_names = {}\n",
    "    for i,state in enumerate(dfa):\n",
    "        if state != \"startingState\":\n",
    "            new_states_names[state] = \"S\"+str(i-1)\n",
    "    print(new_states_names)\n",
    "\n",
    "    # replace states with their new names\n",
    "    new_dfa = dfa.copy()\n",
    "\n",
    "    for key in dfa:\n",
    "        if key != \"startingState\":\n",
    "\n",
    "            for sub_key in dfa[key]:\n",
    "                if sub_key !=\"isTerminatingState\":\n",
    "                    old_state = dfa[key][sub_key]  #('S1', 'S3')\n",
    "                    new_state = new_states_names[old_state] #'S0'\n",
    "                    new_dfa[key][sub_key] = new_state\n",
    "\n",
    "            old_state = key  #('S1', 'S3')\n",
    "            new_state = new_states_names[old_state] #'S0'\n",
    "            new_dfa[new_state]= new_dfa[old_state]\n",
    "            del new_dfa[key]\n",
    "\n",
    "        else:\n",
    "            old_state = dfa[key]\n",
    "            new_state = new_states_names[old_state]\n",
    "            new_dfa[key] = new_state\n",
    "\n",
    "    return new_dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'startingState': ('S1', 'S3'), ('S1', 'S3'): {'isTerminatingState': False, 'a': ('S1', 'S2', 'S3', 'S4', 'S5')}, ('S1', 'S2', 'S3', 'S4', 'S5'): {'isTerminatingState': False, 'a': ('S1', 'S2', 'S3', 'S4', 'S5'), 'b': ('S6',)}, ('S6',): {'isTerminatingState': True}}\n",
      "{('S1', 'S3'): 'S0', ('S1', 'S2', 'S3', 'S4', 'S5'): 'S1', ('S6',): 'S2'}\n",
      "{'startingState': 'S0', 'S0': {'isTerminatingState': False, 'a': 'S1'}, 'S1': {'isTerminatingState': False, 'a': 'S1', 'b': 'S2'}, 'S2': {'isTerminatingState': True}}\n"
     ]
    }
   ],
   "source": [
    "test_nfa= {\n",
    "      \"startingState\": \"S3\",\n",
    "      \"S3\": {\n",
    "            \"isTerminatingState\": False,\n",
    "            \"ε\": \"S1\"\n",
    "      },\n",
    "      \"S4\": {\n",
    "            \"isTerminatingState\": False,\n",
    "            \"ε\": \"S5\"\n",
    "      },\n",
    "      \"S1\": {\n",
    "            \"isTerminatingState\": False,\n",
    "            \"a\": \"S2\"\n",
    "      },\n",
    "      \"S2\": {\n",
    "            \"isTerminatingState\": False,\n",
    "            \"ε\": [\n",
    "                  \"S3\",\n",
    "                  \"S4\"\n",
    "            ]\n",
    "      },\n",
    "      \"S5\": {\n",
    "            \"isTerminatingState\": False,\n",
    "            \"b\": \"S6\"\n",
    "      },\n",
    "      \"S6\": {\n",
    "            \"isTerminatingState\": True\n",
    "      }\n",
    "}\n",
    "\n",
    "test_dfa = convert_nfa_to_dfa(test_nfa)\n",
    "print(test_dfa)\n",
    "final_dfa = get_final_dfa (test_dfa)\n",
    "print(final_dfa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimized DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
